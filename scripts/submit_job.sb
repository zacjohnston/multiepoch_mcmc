#!/bin/bash --login
########## SBATCH Lines for Resource Request ##########
#SBATCH --time=4:00:00        # limit of wall clock time - how long the job will run (same as -t)
#SBATCH --nodes=1             # number of different nodes - could be an exact number or a range of nodes (same as -N)
#SBATCH --ntasks=4            # number of tasks - how many tasks (nodes) that you require (same as -n)
#SBATCH --cpus-per-task=1     # number of CPUs (or cores) per task (same as -c)
#SBATCH --mem-per-cpu=1G      # memory required per allocated CPU (or core) - amount of memory (in bytes)
#SBATCH --job-name mcmc       # you can give your job a name for easier identification (same as -J)
#SBATCH --mail-user=zacjohn@msu.edu
#SBATCH --mail-type=BEGIN,END
#SBATCH --account=snaphu
########## Command Lines to Run ##########
if [ -z "${MULTIEPOCH_MCMC}" ]; then
  echo "ERROR: Must set environment variable for repo path, e.g.:"
  echo "  > export MULTIEPOCH_MCMC=~/codes/multiepoch_mcmc"
  exit 1
fi

if [ -z "${n_steps}" ] || [ -z "${n_walkers}" ]; then
  echo "ERROR: Must provide n_steps and n_walkers, e.g.:"
  echo "    > sbatch --export=n_steps=1000,n_walkers=1000 --ntasks=8 submit_job.sb"
  exit 1
fi

conda activate multiepoch_mcmc
cd "${MULTIEPOCH_MCMC}/scripts" || exit

python run_mcmc.py "${n_steps}" n_walkers="${n_walkers}" n_threads="${SLURM_NTASKS}"


scontrol show job "${SLURM_JOB_ID}"     ### write job information to output file

